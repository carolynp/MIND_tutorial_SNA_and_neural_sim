{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2c. Extract time series from each ROI\n",
    "\n",
    "**Author: Carolyn Parkinson**\n",
    "\n",
    "**Email: <cparkinson@ucla.edu>**\n",
    "\n",
    "**Lab website: http://csnlab.org**\n",
    "\n",
    "**August 2018**\n",
    "#### Note: Notebooks 2a, 2b and 2c are created just for the purposes of following along and possibly using as a reference in the future, since many of you won't have installed AFNI and since the input files would be very large and would take a long time to download.\n",
    "\n",
    "After preprocessing the EPI data and concatenating pre-processed data across runs, this script:\n",
    "\n",
    "1) Averages the preprocessed time series across voxels within anatomical ROI\n",
    "\n",
    "2) Saves these averaged pre-processed time series for each ROI for each subject in a nested dictionary (*all_subj_roi_ts.json*) formatted like this:\n",
    "\n",
    "*all_ts_dict[subject_id][roi_label] = [t1, t2, ..., tn]*\n",
    "\n",
    "\n",
    "It takes as input:\n",
    "\n",
    "- Each subject's preprocessed data concatenated across runs (*subjectid_epi_all_preprocessed+orig*)\n",
    "\n",
    "- Each subject's Freesurfer parcellation and cortical segmentation\n",
    " file (*aparc+aseg_rank_Alnd_Exp+orig*), which is already in line with their functional data\n",
    "\n",
    "- The table of values and corresponding ROI labels for that subject's FreeSurfer cortical parcellation and tissue segmentation file (*aparc+aseg_rank.niml.lt*)\n",
    "\n",
    "- Lists of subject IDs (*fmri_subjects.json*) and ROIs in *aparc+aseg_rank.niml.lt* to exclude (*exclude_rois.json* -- e.g., white matter, ventricles, non-brain tissue)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "import glob\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_path = \"./data\"\n",
    "\n",
    "# load in list of fMRI subjects\n",
    "with open(\"{}/fmri/fmri_subjects.json\".format(study_path)) as data_file:\n",
    "    subj_list = json.load(data_file)\n",
    "\n",
    "# load in a list of ROI labels to exclude (ventricles, white matter, etc.)\n",
    "with open(\"{}/fmri/exclude_rois.json\".format(study_path)) as data_file:\n",
    "    rois_to_exclude = json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some convenience functions\n",
    "\n",
    "def sh(c):\n",
    "    '''\n",
    "    run shell commands\n",
    "    '''\n",
    "    subprocess.call(c, shell = True)\n",
    "\n",
    "    \n",
    "def ld_writeDicts(filePath, dict):\n",
    "    '''\n",
    "    write dictionaries to files with json encoding\n",
    "    '''\n",
    "    f = open(filePath,'w')\n",
    "    newData = json.dumps(dict, sort_keys = True, indent = 4)\n",
    "    f.write(newData)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ts_dict = {}\n",
    "\n",
    "for subject in subj_list:\n",
    "    \n",
    "    subj_dir = \"{}/fmri/example_subj/{}\".format(study_path, subject)\n",
    "    os.chdir(subj_dir)\n",
    "    \n",
    "    all_epi = \"{}_epi_all_preprocessed+orig\".format(subject)\n",
    "\n",
    "    # specify table of ROI labels from Freesurfer cortical parcellation\n",
    "    lookup_table = \"{}/aparc+aseg_rank.niml.lt\".format(subj_dir)\n",
    "\n",
    "    # create a dictionary to fill that matches ROI numbers to labels\n",
    "    roi_dict = {}\n",
    "\n",
    "    with open(lookup_table) as csvfile:\n",
    "        # skip first 4 lines (header)\n",
    "        next(csvfile)\n",
    "        next(csvfile)\n",
    "        next(csvfile)\n",
    "        next(csvfile)\n",
    "        reader = csv.DictReader(csvfile, delimiter = \" \", \n",
    "                                fieldnames = [\"roi_num\", \"roi_label\"])\n",
    "        for row in reader:\n",
    "            roi_dict[row['roi_num']] = row['roi_label']\n",
    "\n",
    "    # save as text file with json encoding; \n",
    "    # these can vary a bit from subject to subject\n",
    "    ld_writeDicts('{}_roi_dict_dk_atlas.json'.format(subject), roi_dict)\n",
    "\n",
    "    # now make masks of cortical areas from Freesurfer parcellation \n",
    "    # so that we can extract the average time series from each mask.\n",
    "\n",
    "    # Get the total number of ROIs in this subject's parcellation file; this is\n",
    "    # 1 less than the length of the lookup table due to the file footer. The\n",
    "    # length of different subjects' lookup tables may vary a bit, as some\n",
    "    # subjects have a 5th ventricle in the FreeSurfer subcortical segmentation;\n",
    "    # see http://surfer.nmr.mgh.harvard.edu/fswiki/SubcorticalSegmentation/\n",
    "    all_roi_num = range(1, (len(roi_dict)-1))\n",
    "\n",
    "    # get Freesurfer parcellation file that's been aligned to our anatomical scan\n",
    "    aparc = \"aparc+aseg_rank_Alnd_Exp\"\n",
    "\n",
    "    # resample parcellation file to functional resolution\n",
    "    resamp_cmd = (\"3dresample -master {} -rmode NN \"\n",
    "                  \"-input {}+orig -prefix {}_3mm\").format(all_epi, aparc, aparc)\n",
    "    sh(resamp_cmd)\n",
    "\n",
    "    # dictionary to store preprocessed time series indexed by ROI\n",
    "    subj_ts_dict = {}\n",
    "\n",
    "    for roi_id in all_roi_num:\n",
    "        # extract ROI label form ROI dictionary\n",
    "        label_roi = roi_dict[str(roi_id)]\n",
    "        \n",
    "        if label_roi not in rois_to_exclude:\n",
    "\n",
    "            # extract the average time series across voxels that ROI\n",
    "            avg_cmd = (\"\"\"3dmaskave -quiet -mask {}_3mm+orig\"<{}..{}>\" {} > avg_{}.1D\"\"\").format(aparc, roi_id, roi_id, all_epi, label_roi)\n",
    "            sh(avg_cmd)\n",
    "\n",
    "\n",
    "            # then read in the 1D file generated by the above command (average time\n",
    "            # series across voxels within a given ROI) and add it to a dictionary\n",
    "            # indexed by ROI label\n",
    "            this_vec = \"avg_{}.1D\".format(label_roi)\n",
    "            subj_ts_dict[label_roi] = np.loadtxt(this_vec).tolist()    \n",
    "    \n",
    "    # move the individual ROI-wise time series 1D files to their own sub-directory   \n",
    "    avg_ts_dir = \"{}/avg\".format(subj_dir)\n",
    "    if not os.path.exists(avg_ts_dir):\n",
    "        os.makedirs(avg_ts_dir)\n",
    "    mv_sub_cmd = \"mv avg*1D {}/\".format(avg_ts_dir)\n",
    "    sh(mv_sub_cmd)\n",
    "\n",
    "    # add this subject's time series data for 80 ROIs to master dictionary\n",
    "    all_ts_dict[subject] = subj_ts_dict\n",
    "\n",
    "# save dictionary of all subjects' data for all 80 ROIs to a json file\n",
    "ld_writeDicts('{}/all_subj_roi_ts.json'.format(study_path), all_ts_dict)\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
